{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def months_difference(date1: str, date2: str) -> int:\n",
        "    date1 = re.sub(r\"-\", \"/\", date1)\n",
        "    date2 = re.sub(r\"-\", \"/\", date2)\n",
        "    # Convert string dates to datetime objects\n",
        "    d1 = datetime.strptime(date1, \"%Y/%m/%d\")\n",
        "    d2 = datetime.strptime(date2, \"%Y/%m/%d\")\n",
        "\n",
        "    # Calculate the difference in years and months\n",
        "    year_diff = d2.year - d1.year\n",
        "    month_diff = d2.month - d1.month\n",
        "\n",
        "    # Total months difference\n",
        "    total_months = year_diff * 12 + month_diff\n",
        "\n",
        "    return total_months"
      ],
      "metadata": {
        "id": "O8yPuV6lqaXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# File paths\n",
        "input_csv = '/content/trajectory_love.csv'  # Input CSV file path\n",
        "output_csv = 'output_AO3.csv'  # Output CSV file path\n",
        "\n",
        "# Initialize a dictionary to hold data grouped by title\n",
        "title_data = {}\n",
        "\n",
        "# Read the input CSV\n",
        "with open(input_csv, 'r', newline='', encoding='utf-8') as infile:\n",
        "    reader = csv.DictReader(infile)\n",
        "\n",
        "    # Group rows by title and accumulate keywords and romantic categories\n",
        "    for row in reader:\n",
        "        title = row['id']\n",
        "\n",
        "        if title not in title_data:\n",
        "            # Initialize the title's entry with the first row's data\n",
        "            title_data[title] = {\n",
        "                'id': row['id'],\n",
        "                'kudos': row['kudos'],\n",
        "                'title': row['title'],\n",
        "                'romanticCategory': set([row['romanticCategory']]),  # Start with a list containing the first romantic category\n",
        "                'rating': row['rating'],\n",
        "                'contentWarning': row['contentWarning'],\n",
        "                'words': row['words'],\n",
        "                'packaged': row['packaged'],\n",
        "                'published': row['published'],\n",
        "                'keywords': set([row['keyword']])  # Start with a list containing the first keyword\n",
        "            }\n",
        "        else:\n",
        "            # Add the current row's keyword to the existing list for this title\n",
        "            title_data[title]['keywords'].add(row['keyword'])\n",
        "            # Add the current row's romantic category to the existing list for this title\n",
        "            if row['romanticCategory'] not in title_data[title]['romanticCategory']:\n",
        "                title_data[title]['romanticCategory'].add(row['romanticCategory'])\n",
        "\n",
        "# Write the result to a new CSV\n",
        "with open(output_csv, 'w', newline='', encoding='utf-8') as outfile:\n",
        "    # Define the fieldnames\n",
        "    fieldnames = ['id', 'kudos', 'title', 'keywords', 'amount_keywords', 'romanticCategory', 'amount_romanticCategory', 'rating', 'contentWarning', 'words', 'packaged', 'published', \"up_time\"]\n",
        "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write each title with its associated data and list of keywords\n",
        "    for title, data in title_data.items():\n",
        "        writer.writerow({\n",
        "            'id': data['id'],\n",
        "            'kudos': data['kudos'],\n",
        "            'title': data['title'],\n",
        "            'keywords': ', '.join(data['keywords']),  # Convert the list back to a string of keywords\n",
        "            'amount_keywords': len(data['keywords']),\n",
        "            'romanticCategory': ', '.join(data['romanticCategory']),  # Convert the list back to a string of romantic categories\n",
        "            'amount_romanticCategory': len(data['romanticCategory']),\n",
        "            'rating': data['rating'],\n",
        "            'contentWarning': data['contentWarning'],\n",
        "            'words': data['words'],\n",
        "            'packaged': data['packaged'],\n",
        "            'published': data['published'],\n",
        "            'up_time': months_difference(data['published'], data['packaged'][:-9])\n",
        "        })"
      ],
      "metadata": {
        "id": "DSub5vbZm5ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bo0x2rIhlJB",
        "outputId": "25f76bf8-cccd-47d8-e41e-8861bb66752c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "def create_word2vec(df, columns, vector_size=100, window=5, min_count=1):\n",
        "    # Create Word2Vec representations for each column in the list\n",
        "    for column in columns:\n",
        "        # Tokenize the column (assuming each row is a string)\n",
        "        tokenized_column = df[column].apply(lambda x: str(x).split())\n",
        "\n",
        "        # Train Word2Vec model for this column\n",
        "        model = Word2Vec(sentences=tokenized_column, vector_size=vector_size, window=window, min_count=min_count)\n",
        "\n",
        "        # Replace the original column with Word2Vec vector representations\n",
        "        df[column] = tokenized_column.apply(lambda tokens: model.wv[tokens].mean(axis=0) if tokens else [0] * vector_size)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = pd.read_csv('/content/output_AO3.csv')\n",
        "columns_to_transform = ['keywords', 'rating', 'contentWarning', 'romanticCategory']  # Update with your column names\n",
        "\n",
        "# Create Word2Vec representations and overwrite columns\n",
        "df_transformed = create_word2vec(df, columns_to_transform)\n",
        "df.to_csv('word2vec_representation_overwritten.csv', index=False)\n",
        "\n",
        "print(df_transformed.head())"
      ],
      "metadata": {
        "id": "GBk8u8p6yR1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38c9253-453f-46f7-c7c3-d42fe7ae323e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  kudos                                      title  \\\n",
            "0  27042589     11                                    Bridges   \n",
            "1  13681566    177                       Entirely by Accident   \n",
            "2  13791840     18                     Nobody's Second Choice   \n",
            "3  14301855    294  An Unusual Request and One Hell of a Deal   \n",
            "4  15128201    180                                  won't he?   \n",
            "\n",
            "                                            keywords  amount_keywords  \\\n",
            "0  [-0.01621489, 0.019760534, 0.01753785, 0.00889...                7   \n",
            "1  [-0.03754358, 0.04080964, 0.039701052, 0.01872...                5   \n",
            "2  [-0.062019784, 0.062396917, 0.05589096, 0.0271...                2   \n",
            "3  [-0.025074823, 0.024605813, 0.023887193, 0.011...               19   \n",
            "4  [-0.019761443, 0.020010946, 0.020477148, 0.008...               14   \n",
            "\n",
            "                                    romanticCategory  amount_romanticCategory  \\\n",
            "0  [-0.004352052, 0.0034430432, -0.00083210086, 0...                        2   \n",
            "1  [-0.00053622725, 0.00023643136, 0.0051033497, ...                        1   \n",
            "2  [-0.008650424, 0.0036913534, 0.005181739, 0.00...                        1   \n",
            "3  [-0.00053622725, 0.00023643136, 0.0051033497, ...                        1   \n",
            "4  [-0.008650424, 0.0036913534, 0.005181739, 0.00...                        1   \n",
            "\n",
            "                                              rating  \\\n",
            "0  [9.456396e-05, 0.0030773198, -0.006812645, -0....   \n",
            "1  [0.008137361, -0.004443177, 0.0039615417, 0.00...   \n",
            "2  [-0.009255024, 0.006382375, 0.0046898294, 0.00...   \n",
            "3  [-0.00053622725, 0.00023643136, 0.0051033497, ...   \n",
            "4  [-0.009255024, 0.006382375, 0.0046898294, 0.00...   \n",
            "\n",
            "                                      contentWarning  words  \\\n",
            "0  [0.000945908, -1.9124709e-05, 0.0036234446, -0...  15011   \n",
            "1  [-0.0057156477, 0.005403255, 0.0015647466, 0.0...  15251   \n",
            "2  [-0.0057156477, 0.005403255, 0.0015647466, 0.0...    443   \n",
            "3  [-0.0057156477, 0.005403255, 0.0015647466, 0.0...   7461   \n",
            "4  [-0.004629352, 0.00292713, 0.003108216, 0.0047...   9164   \n",
            "\n",
            "              packaged   published  up_time  \n",
            "0  2022-04-16T04:39:16  2020-10-16       18  \n",
            "1  2022-01-29T15:58:04  2018-02-14       47  \n",
            "2  2022-01-30T12:23:16  2018-02-24       47  \n",
            "3  2022-01-29T04:33:48  2018-04-13       45  \n",
            "4  2022-02-12T07:09:48  2018-07-01       43  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('/content/output_AO3.csv')\n",
        "\n",
        "# Keywords to search for (case-sensitive)\n",
        "keywords_list = [\"Enemies to Lovers\", \"e2l\", \"enemies to lovers\", \"E2L\"]\n",
        "\n",
        "# Initialize a dictionary to store the counts for each keyword\n",
        "keyword_counts = {keyword: 0 for keyword in keywords_list}\n",
        "\n",
        "# Go through the 'keywords' column and count occurrences of each keyword\n",
        "for entry in df['keywords']:\n",
        "    for keyword in keywords_list:\n",
        "        # Count the occurrences of each keyword in the current entry\n",
        "        keyword_counts[keyword] += entry.count(keyword)\n",
        "\n",
        "# Print the results\n",
        "for keyword, count in keyword_counts.items():\n",
        "    print(f\"'{keyword}': {count} occurrences\")\n",
        "\n",
        "# Count the total number of entries (rows) in the DataFrame\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm3CCrLwm6Ml",
        "outputId": "71a8e1d1-d748-4846-c245-49cf4e64fd9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Enemies to Lovers': 94 occurrences\n",
            "'e2l': 0 occurrences\n",
            "'enemies to lovers': 0 occurrences\n",
            "'E2L': 0 occurrences\n",
            "364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf = pd.read_csv('/content/word2vec_representation_overwritten.csv')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n",
        "def convert_to_float_list(string):\n",
        "    # Remove unwanted characters (brackets, newline) using regex\n",
        "    clean_string = re.sub(r'[\\[\\]\\n]', '', string)\n",
        "\n",
        "    # Split the string into components\n",
        "    string_list = clean_string.split()\n",
        "\n",
        "    # Convert each component to a float\n",
        "    float_list = [float(num) for num in string_list]\n",
        "\n",
        "    return float_list\n",
        "\n",
        "def convert_columns_to_word2vec(df, columns):\n",
        "    # Loop through the specified columns\n",
        "    for column in columns:\n",
        "        # Apply the conversion to each row in the column\n",
        "        df[column] = df[column].apply(lambda row: convert_to_float_list(row))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Specify the columns to convert\n",
        "columns_to_convert = ['keywords', 'rating', 'contentWarning', 'romanticCategory']\n",
        "\n",
        "# Apply the conversion to the specified columns\n",
        "df_transformed = convert_columns_to_word2vec(tf_idf, columns_to_convert)\n",
        "\n",
        "df_transformed['keywords_mean'] = df_transformed['keywords'].apply(np.mean)\n",
        "df_transformed['keywords_max'] = df_transformed['keywords'].apply(np.max)\n",
        "df_transformed['keywords_min'] = df_transformed['keywords'].apply(np.min)\n",
        "\n",
        "df_transformed['rating_mean'] = df_transformed['rating'].apply(np.mean)\n",
        "df_transformed['rating_max'] = df_transformed['rating'].apply(np.max)\n",
        "df_transformed['rating_min'] = df_transformed['rating'].apply(np.min)\n",
        "\n",
        "df_transformed['contentWarning_mean'] = df_transformed['contentWarning'].apply(np.mean)\n",
        "df_transformed['contentWarning_max'] = df_transformed['contentWarning'].apply(np.max)\n",
        "df_transformed['contentWarning_min'] = df_transformed['contentWarning'].apply(np.min)\n",
        "\n",
        "df_transformed['romanticCategory_mean'] = df_transformed['romanticCategory'].apply(np.mean)\n",
        "df_transformed['romanticCategory_max'] = df_transformed['romanticCategory'].apply(np.max)\n",
        "df_transformed['romanticCategory_min'] = df_transformed['romanticCategory'].apply(np.min)\n",
        "\n",
        "df_transformed = df_transformed.iloc[:, 13:]\n",
        "\n",
        "print(df_transformed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adgmZ4KPl9f-",
        "outputId": "73c0fc4c-0fc4-467c-f25f-a78d7cf61395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   keywords_mean  keywords_max  keywords_min  rating_mean  rating_max  \\\n",
            "0       0.002877      0.117595     -0.114768    -0.000008    0.009923   \n",
            "1       0.006483      0.271132     -0.268012    -0.000377    0.008188   \n",
            "2       0.009143      0.381607     -0.374412     0.000394    0.009061   \n",
            "3       0.004051      0.168580     -0.164746     0.000157    0.009619   \n",
            "4       0.003227      0.132687     -0.131532     0.000394    0.009061   \n",
            "\n",
            "   rating_min  contentWarning_mean  contentWarning_max  contentWarning_min  \\\n",
            "0   -0.009122             0.000171            0.010017           -0.010721   \n",
            "1   -0.009075             0.000456            0.008414           -0.007713   \n",
            "2   -0.009255             0.000456            0.008414           -0.007713   \n",
            "3   -0.009604             0.000456            0.008414           -0.007713   \n",
            "4   -0.009255             0.000018            0.011680           -0.010382   \n",
            "\n",
            "   romanticCategory_mean  romanticCategory_max  romanticCategory_min  \n",
            "0               0.000333              0.008749             -0.009150  \n",
            "1               0.000157              0.009619             -0.009604  \n",
            "2               0.000680              0.010005             -0.009888  \n",
            "3               0.000157              0.009619             -0.009604  \n",
            "4               0.000680              0.010005             -0.009888  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5PI6YBA341L",
        "outputId": "0da9d98f-13f4-4d0f-df42-951a48972914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  kudos                                      title  \\\n",
            "0  27042589     11                                    Bridges   \n",
            "1  13681566    177                       Entirely by Accident   \n",
            "2  13791840     18                     Nobody's Second Choice   \n",
            "3  14301855    294  An Unusual Request and One Hell of a Deal   \n",
            "4  15128201    180                                  won't he?   \n",
            "\n",
            "                                            keywords  amount_keywords  \\\n",
            "0  Period-Typical Language, A little (implicit) C...                7   \n",
            "1  Implied Sexual Content, Sexual Tension, Fluff ...                5   \n",
            "2   Friends to Lovers, Alternate Universe - Hogwarts                2   \n",
            "3  More angst than i originally intended, Origina...               19   \n",
            "4  very cute, Fluff, summer at the Burrow, lot's ...               14   \n",
            "\n",
            "  romanticCategory  amount_romanticCategory             rating  \\\n",
            "0         M/M, F/M                        2             Mature   \n",
            "1              M/M                        1          Not Rated   \n",
            "2              F/M                        1  General Audiences   \n",
            "3              M/M                        1           Explicit   \n",
            "4              F/M                        1  General Audiences   \n",
            "\n",
            "                              contentWarning  words             packaged  \\\n",
            "0             Graphic Depictions Of Violence  15011  2022-04-16T04:39:16   \n",
            "1                  No Archive Warnings Apply  15251  2022-01-29T15:58:04   \n",
            "2                  No Archive Warnings Apply    443  2022-01-30T12:23:16   \n",
            "3                  No Archive Warnings Apply   7461  2022-01-29T04:33:48   \n",
            "4  Creator Chose Not To Use Archive Warnings   9164  2022-02-12T07:09:48   \n",
            "\n",
            "    published  up_time  \n",
            "0  2020-10-16       18  \n",
            "1  2018-02-14       47  \n",
            "2  2018-02-24       47  \n",
            "3  2018-04-13       45  \n",
            "4  2018-07-01       43  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([df.iloc[:, [1,4,6,9,12]], df_transformed], axis=1)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mjsajw9KAEV9",
        "outputId": "2eb9450d-119d-4e75-8d20-6464d69d7151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   kudos  amount_keywords  amount_romanticCategory  words  up_time  \\\n",
            "0     11                7                        2  15011       18   \n",
            "1    177                5                        1  15251       47   \n",
            "2     18                2                        1    443       47   \n",
            "3    294               19                        1   7461       45   \n",
            "4    180               14                        1   9164       43   \n",
            "\n",
            "   keywords_mean  keywords_max  keywords_min  rating_mean  rating_max  \\\n",
            "0       0.002877      0.117595     -0.114768    -0.000008    0.009923   \n",
            "1       0.006483      0.271132     -0.268012    -0.000377    0.008188   \n",
            "2       0.009143      0.381607     -0.374412     0.000394    0.009061   \n",
            "3       0.004051      0.168580     -0.164746     0.000157    0.009619   \n",
            "4       0.003227      0.132687     -0.131532     0.000394    0.009061   \n",
            "\n",
            "   rating_min  contentWarning_mean  contentWarning_max  contentWarning_min  \\\n",
            "0   -0.009122             0.000171            0.010017           -0.010721   \n",
            "1   -0.009075             0.000456            0.008414           -0.007713   \n",
            "2   -0.009255             0.000456            0.008414           -0.007713   \n",
            "3   -0.009604             0.000456            0.008414           -0.007713   \n",
            "4   -0.009255             0.000018            0.011680           -0.010382   \n",
            "\n",
            "   romanticCategory_mean  romanticCategory_max  romanticCategory_min  \n",
            "0               0.000333              0.008749             -0.009150  \n",
            "1               0.000157              0.009619             -0.009604  \n",
            "2               0.000680              0.010005             -0.009888  \n",
            "3               0.000157              0.009619             -0.009604  \n",
            "4               0.000680              0.010005             -0.009888  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "def make_pred(data):\n",
        "    # Assuming `data` is already defined\n",
        "    x = data.iloc[:, 1:].values\n",
        "    y = data.iloc[:, 0].values\n",
        "    y = y.reshape(len(y), 1)\n",
        "\n",
        "    # Splitting the dataset into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "    # Standardizing the features\n",
        "    sc_x = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    # Fit on training data and transform\n",
        "    X_train = sc_x.fit_transform(X_train)\n",
        "    X_test = sc_x.transform(X_test)  # Use the same scaler to transform the test data\n",
        "\n",
        "    # Fit the target variable scaler only on the training target\n",
        "    y_train = sc_y.fit_transform(y_train)\n",
        "    y_test = sc_y.transform(y_test)  # Transform the test target\n",
        "\n",
        "    # Reshape y_train if necessary\n",
        "    y_train = y_train.ravel()\n",
        "\n",
        "    # Creating and fitting the SVR model\n",
        "    regressor = SVR(kernel='rbf', epsilon=0.001, gamma=\"auto\")\n",
        "    regressor.fit(X_train, y_train)\n",
        "\n",
        "    # Making predictions on the test set\n",
        "    y_pred = regressor.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions and test values to original scale\n",
        "    y_pred_inv = sc_y.inverse_transform(y_pred.reshape(-1, 1)).ravel()\n",
        "    y_test_inv = sc_y.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Calculating metrics\n",
        "    mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
        "    rmse = root_mean_squared_error(y_test_inv, y_pred_inv)\n",
        "\n",
        "    #print(\"Mean Squared Error:\", round(mse, 2))\n",
        "    #print(\"Root Mean Squared Error:\", round(rmse, 2), \"\\n\")\n",
        "\n",
        "    # Printing actual vs predicted values\n",
        "    #for actual, predicted in zip(y_test_inv, y_pred_inv):\n",
        "    #    print(\"Actual value:\", actual, \"Predicted value:\", predicted, \"Difference:\", actual - predicted)\n",
        "    return mse, rmse\n",
        "\n",
        "mse_lst = []\n",
        "rmse_lst = []\n",
        "\n",
        "for i in range(200):\n",
        "    mse, rmse = make_pred(data)\n",
        "    mse_lst.append(mse)\n",
        "    rmse_lst.append(rmse)\n",
        "\n",
        "print(\"Mean Squared Error:\", round(np.mean(mse_lst), 2))\n",
        "print(\"Root Mean Squared Error:\", round(np.mean(rmse_lst), 2))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_7a-I9fgBBQ",
        "outputId": "cc56bb33-bbef-4902-d099-200c884cedbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 624303.06\n",
            "Root Mean Squared Error: 727.83\n"
          ]
        }
      ]
    }
  ]
}